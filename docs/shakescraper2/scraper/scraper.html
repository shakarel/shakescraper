<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.1">
<title>shakescraper2.scraper.scraper API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>shakescraper2.scraper.scraper</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="shakescraper2.scraper.scraper.Scraper"><code class="flex name class">
<span>class <span class="ident">Scraper</span></span>
<span>(</span><span>url: str, notifier: <a title="shakescraper2.scraper.notifier.Notifier" href="notifier.html#shakescraper2.scraper.notifier.Notifier">Notifier</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>A class used to scrape content from a given URL.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>url</code></strong> :&ensp;<code>str</code></dt>
<dd>The URL to be scraped.</dd>
<dt><strong><code>notifier</code></strong> :&ensp;<code>Notifier</code></dt>
<dd>An instance of the Notifier class used to send notifications.</dd>
</dl>
<h2 id="methods">Methods</h2>
<p>scrape() -&gt; str
Scrapes content from the URL based on its content type and returns it as a string.
_scrape_html(response) -&gt; str
Extracts and prettifies HTML content from the response.
_scrape_xml(response) -&gt; str
Extracts and formats XML content from the response.
_scrape_json(response) -&gt; str
Extracts and formats JSON content from the response.
_scrape_plain_text(response) -&gt; str
Extracts plain text content from the response.</p>
<p>Initializes the Scraper with a URL and a notifier instance.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>url</code></strong> :&ensp;<code>str</code></dt>
<dd>The URL to be scraped.</dd>
<dt><strong><code>notifier</code></strong> :&ensp;<code>Notifier</code></dt>
<dd>An instance of the Notifier class to send notifications after scraping.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Scraper:
    &#34;&#34;&#34;
    A class used to scrape content from a given URL.

    Attributes
    ----------
    url : str
        The URL to be scraped.
    notifier : Notifier
        An instance of the Notifier class used to send notifications.

    Methods
    -------
    scrape() -&gt; str
        Scrapes content from the URL based on its content type and returns it as a string.
    _scrape_html(response) -&gt; str
        Extracts and prettifies HTML content from the response.
    _scrape_xml(response) -&gt; str
        Extracts and formats XML content from the response.
    _scrape_json(response) -&gt; str
        Extracts and formats JSON content from the response.
    _scrape_plain_text(response) -&gt; str
        Extracts plain text content from the response.
    &#34;&#34;&#34;

    def __init__(self, url: str, notifier: Notifier) -&gt; None:
        &#34;&#34;&#34;
        Initializes the Scraper with a URL and a notifier instance.

        Parameters
        ----------
        url : str
            The URL to be scraped.
        notifier : Notifier
            An instance of the Notifier class to send notifications after scraping.
        &#34;&#34;&#34;
        self.url = url
        self.notifier = notifier

    def scrape(self) -&gt; str:
        &#34;&#34;&#34;
        Scrapes content from the URL based on its content type.

        Depending on the content type of the URL, this method delegates to specific
        scraping methods for HTML, XML, JSON, or plain text.

        Returns
        -------
        str
            The scraped content as a string.

        Raises
        ------
        RuntimeError
            If the request to the URL fails or the content type is unsupported.
        &#34;&#34;&#34;
        try:
            response = requests.get(self.url)
            response.raise_for_status()

            content_type = response.headers.get(&#39;Content-Type&#39;)
            if &#39;html&#39; in content_type:
                content = self._scrape_html(response)
            elif &#39;xml&#39; in content_type or &#39;application/xml&#39; in content_type:
                content = self._scrape_xml(response)
            elif &#39;json&#39; in content_type:
                content = self._scrape_json(response)
            elif &#39;text&#39; in content_type:
                content = self._scrape_plain_text(response)
            else:
                raise ValueError(f&#34;Unsupported content type: {content_type}&#34;)

            self.notifier.notify_offline_components(url=self.url, status=&#34;scraping complete&#34;, content=content)
            return content

        except requests.exceptions.RequestException as e:
            raise RuntimeError(f&#34;Failed to scrape data: {str(e)}&#34;)

    def _scrape_html(self, response) -&gt; str:
        &#34;&#34;&#34;
        Extracts and prettifies HTML content from the response.

        Parameters
        ----------
        response : requests.Response
            The HTTP response object containing HTML content.

        Returns
        -------
        str
            The prettified HTML content as a string.
        &#34;&#34;&#34;
        html_content = BeautifulSoup(response.content, &#34;html.parser&#34;)
        return html_content.prettify()

    def _scrape_xml(self, response) -&gt; str:
        &#34;&#34;&#34;
        Extracts and formats XML content from the response.

        Parameters
        ----------
        response : requests.Response
            The HTTP response object containing XML content.

        Returns
        -------
        str
            The formatted XML content as a string.
        &#34;&#34;&#34;
        data = ET.fromstring(response.content)
        return ET.tostring(data, encoding=&#34;unicode&#34;, method=&#34;xml&#34;)

    def _scrape_json(self, response) -&gt; str:
        &#34;&#34;&#34;
        Extracts and formats JSON content from the response.

        Parameters
        ----------
        response : requests.Response
            The HTTP response object containing JSON content.

        Returns
        -------
        str
            The formatted JSON content as a string.
        &#34;&#34;&#34;
        data = response.json()
        return json.dumps(data, indent=4)

    def _scrape_plain_text(self, response) -&gt; str:
        &#34;&#34;&#34;
        Extracts plain text content from the response.

        Parameters
        ----------
        response : requests.Response
            The HTTP response object containing plain text content.

        Returns
        -------
        str
            The plain text content as a string.
        &#34;&#34;&#34;
        return response.text</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="shakescraper2.scraper.scraper.Scraper.scrape"><code class="name flex">
<span>def <span class="ident">scrape</span></span>(<span>self) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Scrapes content from the URL based on its content type.</p>
<p>Depending on the content type of the URL, this method delegates to specific
scraping methods for HTML, XML, JSON, or plain text.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>The scraped content as a string.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If the request to the URL fails or the content type is unsupported.</dd>
</dl></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="shakescraper2.scraper" href="index.html">shakescraper2.scraper</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="shakescraper2.scraper.scraper.Scraper" href="#shakescraper2.scraper.scraper.Scraper">Scraper</a></code></h4>
<ul class="">
<li><code><a title="shakescraper2.scraper.scraper.Scraper.scrape" href="#shakescraper2.scraper.scraper.Scraper.scrape">scrape</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.1</a>.</p>
</footer>
</body>
</html>
